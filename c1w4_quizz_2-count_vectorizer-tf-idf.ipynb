{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset https://www.coursera.org/learn/ml-foundations/supplement/6DeQc/retrieving-wikipedia-articles-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./input/people_wiki.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URI            name  \\\n",
       "0   <http://dbpedia.org/resource/Digby_Morrell>   Digby Morrell   \n",
       "1  <http://dbpedia.org/resource/Alfred_J._Lewy>  Alfred J. Lewy   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top word count words for Elton John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elton=df[df[\"name\"]==\"Elton John\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vecotirzer :D \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count = count_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = count_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is already a dict with words and number of occurrences\n",
    "vocabulary = count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(doc):\n",
    "    dic = {}\n",
    "    if analyzer(doc):\n",
    "        M = count_vectorizer.fit_transform([doc]).toarray()[0]\n",
    "        for word,index in vocabulary.items():\n",
    "            dic[word] = M[index]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vargas/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "elton['word_count'] = elton['text'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Elton_John&gt;</td>\n",
       "      <td>Elton John</td>\n",
       "      <td>sir elton hercules john cbe born reginald kenn...</td>\n",
       "      <td>{'sir': 1, 'elton': 3, 'hercules': 1, 'john': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URI        name  \\\n",
       "19923  <http://dbpedia.org/resource/Elton_John>  Elton John   \n",
       "\n",
       "                                                    text  \\\n",
       "19923  sir elton hercules john cbe born reginald kenn...   \n",
       "\n",
       "                                              word_count  \n",
       "19923  {'sir': 1, 'elton': 3, 'hercules': 1, 'john': ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>the</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>in</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>and</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>has</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "56  the     27\n",
       "60   in     18\n",
       "21  and     15\n",
       "55   of     13\n",
       "25  has      9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a table with dict of words and occurrences\n",
    "elton_count_table = pd.DataFrame(elton['word_count'].values[0].items(),columns=['word','count'])\n",
    "elton_count_table.sort_values(by='count',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top TF-IDF words for Elton John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "# term frequency–inverse document frequency, the tf–idf value increases proportionally to the number of \n",
    "# times a word appears in the document and is offset by the number of documents in the corpus that \n",
    "# contain the word, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 252)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = tf_idf_vectorizer.fit_transform(list(elton[\"text\"]))\n",
    "print( tf_idf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a matrix, and we need a list to append to the dataset\n",
    "arrays_of_list = tf_idf_matrix.tolil().data\n",
    "tf_idf= arrays_of_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending this list to the dataframe\n",
    "elton_count_table[\"tf_idf\"]=tf_idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>openly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>number</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>charitable</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>impact</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  count    tf_idf\n",
       "227      openly      1  0.563848\n",
       "135      number      2  0.375898\n",
       "42           30      1  0.313249\n",
       "176  charitable      1  0.271482\n",
       "118      impact      1  0.187949"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elton_count_table.sort_values(by='tf_idf',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cosine distance between 'Elton John's and 'Victoria Beckham's articles (represented with TF-IDF) falls within which range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "elton\n",
    "victoria = df[df['name'] == 'Victoria Beckham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in previous quizz is calculated \"mathematically\" the cosine distance from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to calculate again the tf-idf for victoria. I should have read this before and made a function,\n",
    "# but lets be pragmatic\n",
    "tf_idf_matrix = tf_idf_vectorizer.fit_transform(list(victoria[\"text\"]))\n",
    "arrays_of_list = tf_idf_matrix.tolil().data\n",
    "tf_idf= arrays_of_list.tolist()\n",
    "victoria_tf_idf=pd.DataFrame()\n",
    "victoria_tf_idf[\"tf_idf\"]=tf_idf[0]\n",
    "victoria_tf_idf.sort_values(by='tf_idf',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victoria_tf_idf[\"tf_idf\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elton_count_table[\"tf_idf\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.02088324 0.06264973 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324 0.02088324\n 0.02088324 0.04176649 0.04176649 0.02088324 0.02088324 0.06264973\n 0.31324867 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.08353298 0.02088324 0.10441622 0.06264973 0.02088324 0.02088324\n 0.02088324 0.06264973 0.02088324 0.02088324 0.04176649 0.08353298\n 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.06264973 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.10441622 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.04176649 0.1879492  0.02088324\n 0.02088324 0.14618271 0.02088324 0.02088324 0.02088324 0.06264973\n 0.08353298 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.3758984  0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324\n 0.08353298 0.04176649 0.14618271 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.04176649 0.06264973 0.06264973 0.02088324\n 0.02088324 0.06264973 0.02088324 0.02088324 0.02088324 0.06264973\n 0.04176649 0.02088324 0.27148218 0.12529947 0.06264973 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.10441622\n 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.02088324 0.02088324 0.02088324 0.02088324 0.06264973 0.5638476\n 0.02088324 0.02088324 0.02088324 0.08353298 0.02088324 0.02088324\n 0.08353298 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-a9facee7f02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosine_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melton_count_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf_idf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvictoria_tf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf_idf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \"\"\"\n\u001b[1;32m    830\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    144\u001b[0m         X = check_array(X, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[1;32m    145\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    147\u001b[0m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[1;32m    148\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.02088324 0.06264973 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324 0.02088324\n 0.02088324 0.04176649 0.04176649 0.02088324 0.02088324 0.06264973\n 0.31324867 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.08353298 0.02088324 0.10441622 0.06264973 0.02088324 0.02088324\n 0.02088324 0.06264973 0.02088324 0.02088324 0.04176649 0.08353298\n 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.06264973 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.10441622 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.04176649 0.1879492  0.02088324\n 0.02088324 0.14618271 0.02088324 0.02088324 0.02088324 0.06264973\n 0.08353298 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.02088324 0.3758984  0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.06264973 0.02088324\n 0.08353298 0.04176649 0.14618271 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324\n 0.02088324 0.02088324 0.04176649 0.06264973 0.06264973 0.02088324\n 0.02088324 0.06264973 0.02088324 0.02088324 0.02088324 0.06264973\n 0.04176649 0.02088324 0.27148218 0.12529947 0.06264973 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.02088324 0.02088324 0.02088324 0.04176649 0.02088324 0.10441622\n 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324 0.02088324\n 0.04176649 0.02088324 0.02088324 0.02088324 0.04176649 0.04176649\n 0.02088324 0.02088324 0.02088324 0.02088324 0.06264973 0.5638476\n 0.02088324 0.02088324 0.02088324 0.08353298 0.02088324 0.02088324\n 0.08353298 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324\n 0.02088324 0.02088324 0.02088324 0.02088324 0.02088324 0.04176649\n 0.02088324 0.02088324 0.04176649 0.02088324 0.02088324 0.02088324].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "cosine_distances(elton_count_table[\"tf_idf\"],victoria_tf_idf[\"tf_idf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cosine distance between 'Elton John's and 'Paul McCartney's articles (represented with TF-IDF) falls within which range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is closer to 'Elton John', 'Victoria Beckham' or 'Paul McCartney'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is the nearest cosine-distance neighbor to 'Elton John' using raw word counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is the nearest cosine-distance neighbor to 'Elton John' using TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is the nearest cosine-distance neighbor to 'Victoria Beckham' using raw word counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is the nearest cosine-distance neighbor to 'Victoria Beckham' using TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsklearn",
   "language": "python",
   "name": "mlsklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
